{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport glob\nimport pandas as pd\nimport random\nimport numpy as np\nimport cv2\nimport base64\nimport imageio\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom copy import deepcopy\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\nfrom pprint import pprint\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport os\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint('Training on',DEVICE)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-25T15:55:03.029130Z","iopub.execute_input":"2021-10-25T15:55:03.029394Z","iopub.status.idle":"2021-10-25T15:55:06.576255Z","shell.execute_reply.started":"2021-10-25T15:55:03.029343Z","shell.execute_reply":"2021-10-25T15:55:06.575558Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATASET_PATH =\"/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/\"\nATTRIBUTES_PATH = \"/kaggle/input/lfw-attributes/lfw_attributes.txt\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:55:12.184074Z","iopub.execute_input":"2021-10-25T15:55:12.184372Z","iopub.status.idle":"2021-10-25T15:55:12.190825Z","shell.execute_reply.started":"2021-10-25T15:55:12.184320Z","shell.execute_reply":"2021-10-25T15:55:12.189853Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Explore the data","metadata":{}},{"cell_type":"code","source":"dataset = []\nfor path in glob.iglob(os.path.join(DATASET_PATH, \"**\", \"*.jpg\")):\n    person = path.split(\"/\")[-2]\n    dataset.append({\"person\":person, \"path\": path})\n    \ndataset = pd.DataFrame(dataset)\n#too much Bush\ndataset = dataset.groupby(\"person\").filter(lambda x: len(x) < 25 )\ndataset.head(10)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-10-25T15:55:19.416070Z","iopub.execute_input":"2021-10-25T15:55:19.416434Z","iopub.status.idle":"2021-10-25T15:55:44.904776Z","shell.execute_reply.started":"2021-10-25T15:55:19.416376Z","shell.execute_reply":"2021-10-25T15:55:44.903715Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i in range(20):\n    idx = random.randint(0, len(dataset))\n    img = plt.imread(dataset.path.iloc[idx])\n    plt.subplot(4, 5, i+1)\n    plt.imshow(img)\n    plt.title(dataset.person.iloc[idx])\n    plt.xticks([])\n    plt.yticks([])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:55:57.339181Z","iopub.execute_input":"2021-10-25T15:55:57.339483Z","iopub.status.idle":"2021-10-25T15:55:59.011821Z","shell.execute_reply.started":"2021-10-25T15:55:57.339430Z","shell.execute_reply":"2021-10-25T15:55:59.011136Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the dataset","metadata":{}},{"cell_type":"code","source":"def fetch_dataset(dx=80,dy=80, dimx=45,dimy=45):\n    \n    df_attrs = pd.read_csv(ATTRIBUTES_PATH, sep='\\t', skiprows=1,) \n    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n    \n    photo_ids = []\n    for dirpath, dirnames, filenames in os.walk(DATASET_PATH):\n        for fname in filenames:\n            if fname.endswith(\".jpg\"):\n                fpath = os.path.join(dirpath,fname)\n                photo_id = fname[:-4].replace('_',' ').split()\n                person_id = ' '.join(photo_id[:-1])\n                photo_number = int(photo_id[-1])\n                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n\n    photo_ids = pd.DataFrame(photo_ids)\n    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n\n    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n    \n    all_photos = df['photo_path'].apply(imageio.imread)\\\n                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n                                .apply(lambda img: np.array(Image.fromarray(img).resize([dimx,dimy])) )\n\n    all_photos = np.stack(all_photos.values).astype('uint8')\n    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n    \n    return all_photos,all_attrs","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:56:09.548293Z","iopub.execute_input":"2021-10-25T15:56:09.548581Z","iopub.status.idle":"2021-10-25T15:56:09.561153Z","shell.execute_reply.started":"2021-10-25T15:56:09.548527Z","shell.execute_reply":"2021-10-25T15:56:09.560115Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data, attrs = fetch_dataset()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:56:28.318313Z","iopub.execute_input":"2021-10-25T15:56:28.318599Z","iopub.status.idle":"2021-10-25T15:57:37.829211Z","shell.execute_reply.started":"2021-10-25T15:56:28.318549Z","shell.execute_reply":"2021-10-25T15:57:37.828425Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#45,45\nIMAGE_H = data.shape[1]\nIMAGE_W = data.shape[2]\n\nN_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:57:37.830944Z","iopub.execute_input":"2021-10-25T15:57:37.831243Z","iopub.status.idle":"2021-10-25T15:57:37.836087Z","shell.execute_reply.started":"2021-10-25T15:57:37.831195Z","shell.execute_reply":"2021-10-25T15:57:37.835270Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data = np.array(data / 255, dtype='float32')\nX_train, X_val = train_test_split(data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:57:45.039445Z","iopub.execute_input":"2021-10-25T15:57:45.039879Z","iopub.status.idle":"2021-10-25T15:57:45.299944Z","shell.execute_reply.started":"2021-10-25T15:57:45.039823Z","shell.execute_reply":"2021-10-25T15:57:45.299254Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = torch.FloatTensor(X_train)\nX_val = torch.FloatTensor(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:57:49.689127Z","iopub.execute_input":"2021-10-25T15:57:49.689427Z","iopub.status.idle":"2021-10-25T15:57:49.696093Z","shell.execute_reply.started":"2021-10-25T15:57:49.689373Z","shell.execute_reply":"2021-10-25T15:57:49.695267Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Building simple autoencoder","metadata":{}},{"cell_type":"code","source":"dim_z=100","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:57:57.044498Z","iopub.execute_input":"2021-10-25T15:57:57.044944Z","iopub.status.idle":"2021-10-25T15:57:57.052559Z","shell.execute_reply.started":"2021-10-25T15:57:57.044772Z","shell.execute_reply":"2021-10-25T15:57:57.050832Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:58:04.642313Z","iopub.execute_input":"2021-10-25T15:58:04.642596Z","iopub.status.idle":"2021-10-25T15:58:04.647937Z","shell.execute_reply.started":"2021-10-25T15:58:04.642546Z","shell.execute_reply":"2021-10-25T15:58:04.647137Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(45*45*3,1500),\n            nn.BatchNorm1d(1500),\n            nn.ReLU(),\n            nn.Linear(1500,1000),\n            nn.BatchNorm1d(1000),\n            nn.ReLU(),\n            nn.Linear(1000, dim_z),\n            nn.BatchNorm1d(dim_z),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(dim_z,1000),\n            nn.BatchNorm1d(1000),\n            nn.ReLU(),\n            #nn.Linear(500,1000),\n            #nn.ReLU(),\n            nn.Linear(1000,1500),\n            nn.BatchNorm1d(1500),\n            nn.ReLU(),\n            nn.Linear(1500,45*45*3)\n        )\n      \n    def encode(self,x):\n        return self.encoder(x)\n    \n    def decode(self,z):\n        return self.decoder(z)\n        \n    def forward(self, x):\n        encoded = self.encode(x) \n        decoded = self.decode(encoded)     \n\n        \n        return encoded, decoded","metadata":{"execution":{"iopub.status.busy":"2021-10-25T15:58:09.858066Z","iopub.execute_input":"2021-10-25T15:58:09.858350Z","iopub.status.idle":"2021-10-25T15:58:09.868335Z","shell.execute_reply.started":"2021-10-25T15:58:09.858301Z","shell.execute_reply":"2021-10-25T15:58:09.867458Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Autoencoder_cnn(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=8, out_channels=16, kernel_size=5, stride=2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(in_channels=16, out_channels=3, kernel_size=5, stride=2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=3, stride=2),\n            #nn.ReLU(),\n            #nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=5, stride=2)\n        )\n        \n    def decode(self,z):\n        return self.decoder(z)\n        \n    def forward(self, x):\n        x = x.permute(0,3,1,2)\n        encoded = self.encoder(x)  \n        decoded = self.decode(encoded)     \n\n        \n        return encoded, decoded","metadata":{"execution":{"iopub.status.busy":"2021-10-25T16:21:55.292000Z","iopub.execute_input":"2021-10-25T16:21:55.292290Z","iopub.status.idle":"2021-10-25T16:21:55.302630Z","shell.execute_reply.started":"2021-10-25T16:21:55.292240Z","shell.execute_reply":"2021-10-25T16:21:55.301802Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model_auto = Autoencoder().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T16:33:16.948501Z","iopub.execute_input":"2021-10-25T16:33:16.948822Z","iopub.status.idle":"2021-10-25T16:33:17.088799Z","shell.execute_reply.started":"2021-10-25T16:33:16.948772Z","shell.execute_reply":"2021-10-25T16:33:17.088157Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# Train autoencoder","metadata":{}},{"cell_type":"code","source":"def get_batch(data, batch_size=64):\n    total_len = data.shape[0]\n    for i in range(0, total_len, batch_size):\n        yield data[i:min(i+batch_size,total_len)]\n\ndef plot_gallery(images, h, w, n_row=3, n_col=6, with_title=False, titles=[]):\n    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        try:\n            plt.imshow(images[i].reshape((h, w, 3)), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n            if with_title:\n                plt.title(titles[i])\n            plt.xticks(())\n            plt.yticks(())\n        except:\n            pass\n        \ndef fit_epoch(model, train_x, criterion, optimizer, batch_size, is_cnn=False):\n    running_loss = 0.0\n    processed_data = 0\n    \n    for inputs in get_batch(train_x,batch_size):\n        \n        if not is_cnn:\n            inputs = inputs.view(-1, 45*45*3)\n        inputs = inputs.to(DEVICE)\n        \n        optimizer.zero_grad()\n        \n        encoder, decoder = model(inputs)\n        \n        #print('decoder shape: ', decoder.shape)\n        \n        if not is_cnn:\n            outputs = decoder.view(-1, 45*45*3)\n        else:\n            outputs = decoder.permute(0,2,3,1)\n        \n        loss = criterion(outputs,inputs)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.shape[0]\n        processed_data += inputs.shape[0]\n    \n    train_loss = running_loss / processed_data    \n    return train_loss\n\ndef eval_epoch(model, x_val, criterion, is_cnn=False):\n    running_loss = 0.0\n    processed_data = 0\n    model.eval()\n    \n    for inputs in get_batch(x_val):\n        if not is_cnn:\n            inputs = inputs.view(-1, 45*45*3)\n        inputs = inputs.to(DEVICE)\n        \n        with torch.set_grad_enabled(False):\n            encoder, decoder = model(inputs)\n            \n            if not is_cnn:\n                outputs = decoder.view(-1, 45*45*3)\n            else:\n                outputs = decoder.permute(0,2,3,1)\n                \n            loss = criterion(outputs,inputs)\n            running_loss += loss.item() * inputs.shape[0]\n            processed_data += inputs.shape[0]\n    \n    val_loss = running_loss / processed_data\n    \n    #draw\n    with torch.set_grad_enabled(False):\n        pic = x_val[3]\n        \n        if not is_cnn:            \n            pic_input = pic.view(-1, 45*45*3)\n        else:\n            pic_input = torch.FloatTensor(pic.unsqueeze(0))\n            \n        pic_input = pic_input.to(DEVICE)        \n        encoder, decoder = model(pic_input)\n        \n        if not is_cnn:\n            pic_output = decoder.view(-1, 45*45*3).squeeze()\n        else:\n            pic_output = decoder.permute(0,2,3,1)\n            \n        pic_output = pic_output.to(\"cpu\")        \n        pic_input = pic_input.to(\"cpu\")\n        plot_gallery([pic_input, pic_output],45,45,1,2)\n    \n    return val_loss\n\ndef train(train_x, val_x, model, epochs=10, batch_size=32, is_cnn=False):     \n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)        \n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss: {val_loss:0.4f}\"\n    \n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        for epoch in range(epochs):            \n            train_loss = fit_epoch(model,train_x,criterion,optimizer,batch_size,is_cnn)\n            val_loss = eval_epoch(model,val_x,criterion, is_cnn)\n            #print(\"loss: \", train_loss)\n\n            history.append((train_loss,val_loss))\n\n            pbar_outer.update(1)\n            #tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss, val_loss=val_loss))            \n        \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-10-25T16:22:09.997568Z","iopub.execute_input":"2021-10-25T16:22:09.997905Z","iopub.status.idle":"2021-10-25T16:22:10.028015Z","shell.execute_reply.started":"2021-10-25T16:22:09.997858Z","shell.execute_reply":"2021-10-25T16:22:10.025571Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"history = train(X_train, X_val, model_auto, epochs=50, batch_size= 64)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T16:22:11.560266Z","iopub.execute_input":"2021-10-25T16:22:11.560578Z","iopub.status.idle":"2021-10-25T16:23:19.998654Z","shell.execute_reply.started":"2021-10-25T16:22:11.560523Z","shell.execute_reply":"2021-10-25T16:23:19.997848Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = zip(*history)\nplt.figure(figsize=(15,10))\nplt.plot(train_loss, label='Train loss')\nplt.plot(val_loss, label='Val loss')\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.plot();","metadata":{"execution":{"iopub.status.busy":"2021-10-25T16:24:22.463170Z","iopub.execute_input":"2021-10-25T16:24:22.463489Z","iopub.status.idle":"2021-10-25T16:24:22.765601Z","shell.execute_reply.started":"2021-10-25T16:24:22.463439Z","shell.execute_reply":"2021-10-25T16:24:22.764907Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# Sampling","metadata":{}},{"cell_type":"markdown","source":"Let's generate some samples from random vectors","metadata":{}},{"cell_type":"code","source":"z = np.random.randn(25, dim_z)\nprint(z.shape)\n\nwith torch.no_grad():\n    inputs = torch.FloatTensor(z)    \n    inputs = inputs.to(DEVICE)\n    model_auto.eval()\n    output = model_auto.decode(inputs)\n    plot_gallery(output.data.cpu().numpy(), IMAGE_H, IMAGE_W, n_row=5, n_col=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T16:27:06.455912Z","iopub.execute_input":"2021-10-25T16:27:06.456257Z","iopub.status.idle":"2021-10-25T16:27:07.518858Z","shell.execute_reply.started":"2021-10-25T16:27:06.456201Z","shell.execute_reply":"2021-10-25T16:27:07.516494Z"},"trusted":true},"execution_count":60,"outputs":[]}]}